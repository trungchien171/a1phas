{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Group 1.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    " \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**IMPORTING LIBRARIES AND DATA**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from tsfracdiff import FractionalDifferentiator\n",
    "from hmmlearn import hmm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    recall_score, precision_score, f1_score, accuracy_score, \n",
    "    classification_report, confusion_matrix, roc_curve, auc, \n",
    "    precision_recall_curve, matthews_corrcoef\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from tpot import TPOTClassifier\n",
    "import ta\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "sns.set(style='dark', palette='viridis')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'forex_lite'\n",
    "files = glob.glob(os.path.join(directory_path, '*.csv'))\n",
    "\n",
    "content = []\n",
    "for i in files:\n",
    "    df = pd.read_csv(i, index_col = 'Date', header = 0)\n",
    "    content.append(df)\n",
    "\n",
    "prices = pd.concat(content, axis = 1)\n",
    "prices.index = pd.to_datetime(prices.index, errors = 'coerce')\n",
    "prices_hourly = prices.resample('1H').last().ffill()\n",
    "prices_daily = prices.resample('1D').last().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EURUSD</th>\n",
       "      <th>GBPUSD</th>\n",
       "      <th>USDJPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>1.42705</td>\n",
       "      <td>1.60877</td>\n",
       "      <td>92.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1.44189</td>\n",
       "      <td>1.60758</td>\n",
       "      <td>92.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1.43675</td>\n",
       "      <td>1.59915</td>\n",
       "      <td>91.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1.44238</td>\n",
       "      <td>1.60237</td>\n",
       "      <td>92.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1.43117</td>\n",
       "      <td>1.59310</td>\n",
       "      <td>93.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>1.07623</td>\n",
       "      <td>1.25454</td>\n",
       "      <td>152.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-04</th>\n",
       "      <td>1.07623</td>\n",
       "      <td>1.25454</td>\n",
       "      <td>152.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-05</th>\n",
       "      <td>1.07572</td>\n",
       "      <td>1.25396</td>\n",
       "      <td>153.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06</th>\n",
       "      <td>1.07662</td>\n",
       "      <td>1.25579</td>\n",
       "      <td>154.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>1.07648</td>\n",
       "      <td>1.25435</td>\n",
       "      <td>154.472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EURUSD   GBPUSD   USDJPY\n",
       "Date                                 \n",
       "2010-01-03  1.42705  1.60877   92.973\n",
       "2010-01-04  1.44189  1.60758   92.270\n",
       "2010-01-05  1.43675  1.59915   91.777\n",
       "2010-01-06  1.44238  1.60237   92.274\n",
       "2010-01-07  1.43117  1.59310   93.316\n",
       "...             ...      ...      ...\n",
       "2024-05-03  1.07623  1.25454  152.847\n",
       "2024-05-04  1.07623  1.25454  152.847\n",
       "2024-05-05  1.07572  1.25396  153.637\n",
       "2024-05-06  1.07662  1.25579  154.225\n",
       "2024-05-07  1.07648  1.25435  154.472\n",
       "\n",
       "[5239 rows x 3 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_daily = prices.resample('D').last().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    " \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**FEATURE ENGINEERING**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_price_features(price: pd.DataFrame, order: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"Create lag features for close price\"\"\"\n",
    "    lag_price = pd.DataFrame(index=price.index)\n",
    "    for i in range(1, order + 1):\n",
    "        lag_price[f'lag_{i}'] = price.shift(i)\n",
    "    return lag_price\n",
    "\n",
    "def regime_hmm(test_data: pd.Series, train_data: pd.Series, n_states: int = 2, n_iter: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Apply Hidden Markov Model to detect regimes in the data and return the probabilities of each state\"\"\"\n",
    "    test_data = test_data.to_frame()\n",
    "    train_data = train_data.to_frame()\n",
    "    \n",
    "    hmm_model = hmm.GaussianHMM(n_iter=n_iter, n_components=n_states, covariance_type='full', init_params='stmc')\n",
    "    hmm_model.fit(train_data)\n",
    "    hmm_probs = hmm_model.predict_proba(test_data)\n",
    "    \n",
    "    hmm_results = pd.DataFrame(index=test_data.index)\n",
    "    for state in range(n_states):\n",
    "        hmm_results[f'hmm_state_{state}'] = hmm_probs[:, state]\n",
    "\n",
    "    return hmm_results\n",
    "\n",
    "def regime_gmm(data: pd.Series, n_states: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"Apply Gaussian Mixture Model to detect regimes in the data and return the probabilities of each state\"\"\"\n",
    "    gmm_model = GaussianMixture(n_components=n_states)\n",
    "    gmm_model.fit(data.to_frame())\n",
    "    gmm_probs = gmm_model.predict_proba(data.to_frame())\n",
    "\n",
    "    gmm_results = pd.DataFrame(index=data.index)\n",
    "    for state in range(n_states):\n",
    "        gmm_results[f'gmm_state_{state}'] = gmm_probs[:, state]\n",
    "\n",
    "    return gmm_results\n",
    "\n",
    "def generate_features(close: pd.Series, lag_order: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"Generate various technical indicators and features from closing prices\"\"\"\n",
    "    returns = close.pct_change().shift(-lag_order)\n",
    "    features = pd.DataFrame()\n",
    "    features['close'] = close\n",
    "    features['returns'] = returns\n",
    "    \n",
    "    features['sma_10'] = ta.trend.sma_indicator(close, window=10)\n",
    "    features['sma_20'] = ta.trend.sma_indicator(close, window=20)\n",
    "    features['sma_100'] = ta.trend.sma_indicator(close, window=100)\n",
    "    features['ema_10'] = ta.trend.ema_indicator(close, window=10)\n",
    "    features['ema_20'] = ta.trend.ema_indicator(close, window=20)\n",
    "    features['ema_100'] = ta.trend.ema_indicator(close, window=100)\n",
    "    features[\"roc_10\"] = ta.momentum.roc(close, window=10, fillna=True)\n",
    "    features[\"roc_20\"] = ta.momentum.roc(close, window=20, fillna=True)\n",
    "    features[\"roc_100\"] = ta.momentum.roc(close, window=100, fillna=True)\n",
    "    features['bb_upper'] = ta.volatility.bollinger_hband(close)\n",
    "    features['bb_middle'] = ta.volatility.bollinger_mavg(close)\n",
    "    features['bb_lower'] = ta.volatility.bollinger_lband(close)\n",
    "\n",
    "    features['rsi_10'] = ta.momentum.rsi(close, window=10, fillna=True)\n",
    "    features['rsi_20'] = ta.momentum.rsi(close, window=20, fillna=True)\n",
    "    features['rsi_100'] = ta.momentum.rsi(close, window=100, fillna=True)\n",
    "    macd_line = np.log(close.ewm(span=12).mean() / close.ewm(span=26).mean())\n",
    "    signal_line = macd_line.ewm(span=9).mean()\n",
    "    features[\"log_macd_hist\"] = macd_line - signal_line\n",
    "    features[\"log_dpo\"] = np.log(close.rolling(11).mean() / close.rolling(20).mean())\n",
    "\n",
    "    gmm_on_return = regime_gmm(features['returns'].dropna(), n_states=2)\n",
    "    features = features.join(gmm_on_return, how='left')\n",
    "\n",
    "    lag_price = create_lag_price_features(close, order=lag_order)\n",
    "    features = features.join(lag_price)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/letianzj/QuantResearch/blob/master/notebooks/gaussian_mixture_markov_switching.ipynb\n",
    "\n",
    "https://letianzj.github.io/gaussian-mixture-markov-regime-switching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>returns</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>sma_20</th>\n",
       "      <th>sma_100</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>ema_100</th>\n",
       "      <th>roc_10</th>\n",
       "      <th>roc_20</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_13</th>\n",
       "      <th>lag_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>1.42705</td>\n",
       "      <td>-0.003024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1.44189</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1.43675</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1.44238</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1.43117</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>1.07623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071016</td>\n",
       "      <td>1.068108</td>\n",
       "      <td>1.079400</td>\n",
       "      <td>1.071204</td>\n",
       "      <td>1.070965</td>\n",
       "      <td>1.078222</td>\n",
       "      <td>0.570024</td>\n",
       "      <td>1.147535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>1.06526</td>\n",
       "      <td>1.06563</td>\n",
       "      <td>1.06561</td>\n",
       "      <td>1.06561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-04</th>\n",
       "      <td>1.07623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071650</td>\n",
       "      <td>1.068695</td>\n",
       "      <td>1.079318</td>\n",
       "      <td>1.072118</td>\n",
       "      <td>1.071466</td>\n",
       "      <td>1.078182</td>\n",
       "      <td>0.592584</td>\n",
       "      <td>1.102876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>1.06526</td>\n",
       "      <td>1.06563</td>\n",
       "      <td>1.06561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-05</th>\n",
       "      <td>1.07572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071966</td>\n",
       "      <td>1.069363</td>\n",
       "      <td>1.079224</td>\n",
       "      <td>1.072773</td>\n",
       "      <td>1.071872</td>\n",
       "      <td>1.078133</td>\n",
       "      <td>0.294622</td>\n",
       "      <td>1.257577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06650</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>1.06526</td>\n",
       "      <td>1.06563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06</th>\n",
       "      <td>1.07662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.072699</td>\n",
       "      <td>1.070095</td>\n",
       "      <td>1.079139</td>\n",
       "      <td>1.073472</td>\n",
       "      <td>1.072324</td>\n",
       "      <td>1.078103</td>\n",
       "      <td>0.685502</td>\n",
       "      <td>1.377602</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07159</td>\n",
       "      <td>1.06650</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>1.06526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>1.07648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073418</td>\n",
       "      <td>1.070580</td>\n",
       "      <td>1.079063</td>\n",
       "      <td>1.074019</td>\n",
       "      <td>1.072720</td>\n",
       "      <td>1.078071</td>\n",
       "      <td>0.672409</td>\n",
       "      <td>0.909278</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07287</td>\n",
       "      <td>1.07159</td>\n",
       "      <td>1.06650</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close   returns    sma_10    sma_20   sma_100    ema_10  \\\n",
       "Date                                                                    \n",
       "2010-01-03  1.42705 -0.003024       NaN       NaN       NaN       NaN   \n",
       "2010-01-04  1.44189  0.004225       NaN       NaN       NaN       NaN   \n",
       "2010-01-05  1.43675 -0.013178       NaN       NaN       NaN       NaN   \n",
       "2010-01-06  1.44238 -0.007845       NaN       NaN       NaN       NaN   \n",
       "2010-01-07  1.43117  0.002234       NaN       NaN       NaN       NaN   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "2024-05-03  1.07623       NaN  1.071016  1.068108  1.079400  1.071204   \n",
       "2024-05-04  1.07623       NaN  1.071650  1.068695  1.079318  1.072118   \n",
       "2024-05-05  1.07572       NaN  1.071966  1.069363  1.079224  1.072773   \n",
       "2024-05-06  1.07662       NaN  1.072699  1.070095  1.079139  1.073472   \n",
       "2024-05-07  1.07648       NaN  1.073418  1.070580  1.079063  1.074019   \n",
       "\n",
       "              ema_20   ema_100    roc_10    roc_20  ...    lag_5    lag_6  \\\n",
       "Date                                                ...                     \n",
       "2010-01-03       NaN       NaN  0.000000  0.000000  ...      NaN      NaN   \n",
       "2010-01-04       NaN       NaN  0.000000  0.000000  ...      NaN      NaN   \n",
       "2010-01-05       NaN       NaN  0.000000  0.000000  ...      NaN      NaN   \n",
       "2010-01-06       NaN       NaN  0.000000  0.000000  ...      NaN      NaN   \n",
       "2010-01-07       NaN       NaN  0.000000  0.000000  ...      NaN      NaN   \n",
       "...              ...       ...       ...       ...  ...      ...      ...   \n",
       "2024-05-03  1.070965  1.078222  0.570024  1.147535  ...  1.07058  1.06929   \n",
       "2024-05-04  1.071466  1.078182  0.592584  1.102876  ...  1.07136  1.07058   \n",
       "2024-05-05  1.071872  1.078133  0.294622  1.257577  ...  1.06650  1.07136   \n",
       "2024-05-06  1.072324  1.078103  0.685502  1.377602  ...  1.07159  1.06650   \n",
       "2024-05-07  1.072720  1.078071  0.672409  0.909278  ...  1.07287  1.07159   \n",
       "\n",
       "              lag_7    lag_8    lag_9   lag_10   lag_11   lag_12   lag_13  \\\n",
       "Date                                                                        \n",
       "2010-01-03      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2010-01-04      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2010-01-05      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2010-01-06      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2010-01-07      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2024-05-03  1.06929  1.07256  1.06989  1.07013  1.06526  1.06563  1.06561   \n",
       "2024-05-04  1.06929  1.06929  1.07256  1.06989  1.07013  1.06526  1.06563   \n",
       "2024-05-05  1.07058  1.06929  1.06929  1.07256  1.06989  1.07013  1.06526   \n",
       "2024-05-06  1.07136  1.07058  1.06929  1.06929  1.07256  1.06989  1.07013   \n",
       "2024-05-07  1.06650  1.07136  1.07058  1.06929  1.06929  1.07256  1.06989   \n",
       "\n",
       "             lag_14  \n",
       "Date                 \n",
       "2010-01-03      NaN  \n",
       "2010-01-04      NaN  \n",
       "2010-01-05      NaN  \n",
       "2010-01-06      NaN  \n",
       "2010-01-07      NaN  \n",
       "...             ...  \n",
       "2024-05-03  1.06561  \n",
       "2024-05-04  1.06561  \n",
       "2024-05-05  1.06563  \n",
       "2024-05-06  1.06526  \n",
       "2024-05-07  1.07013  \n",
       "\n",
       "[5239 rows x 35 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_features(prices_daily['EURUSD'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "close             0\n",
       "returns          14\n",
       "sma_10            9\n",
       "sma_20           19\n",
       "sma_100          99\n",
       "ema_10            9\n",
       "ema_20           19\n",
       "ema_100          99\n",
       "roc_10            0\n",
       "roc_20            0\n",
       "roc_100           0\n",
       "bb_upper         19\n",
       "bb_middle        19\n",
       "bb_lower         19\n",
       "rsi_10            0\n",
       "rsi_20            0\n",
       "rsi_100           0\n",
       "log_macd_hist     0\n",
       "log_dpo          19\n",
       "gmm_state_0      14\n",
       "gmm_state_1      14\n",
       "lag_1             1\n",
       "lag_2             2\n",
       "lag_3             3\n",
       "lag_4             4\n",
       "lag_5             5\n",
       "lag_6             6\n",
       "lag_7             7\n",
       "lag_8             8\n",
       "lag_9             9\n",
       "lag_10           10\n",
       "lag_11           11\n",
       "lag_12           12\n",
       "lag_13           13\n",
       "lag_14           14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    " \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**META LABELLING TRIPLE BARRIER LOPEZ**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-example\">  \n",
    "\n",
    "- Fractionally differentiated log prices are computed to adjust for long-term dependencies in the price series.\n",
    "- Daily volatility with log returns is calculated to capture the level of price fluctuation.\n",
    "- **Primary model**: CUSUM filter events are detected to identify potential trading opportunities based on significant price movements.\n",
    "- **Secondary model**: Triple barrier events are generated to define the boundaries for taking profit or stopping losses in trading strategies.\n",
    "- Labels are assigned to indicate whether a particular trade resulted in a profit, loss, or no action.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fractional differenced log price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ADF test we're aggregating the data to a lower frequency, i.e. to daily data to speed things up cos, when testing properties such as presence of a unit root, what matters is the time span, not the frequency at which the data is sampled (unless the sample is too small for asymptotic inference, that is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fracdiff_log_price(\n",
    "    close: pd.Series,\n",
    ") -> pd.Series:\n",
    "    \"\"\" create fractional differenced log price series \"\"\"\n",
    "    log_prices = np.log(close)\n",
    "    adf_result = adfuller(log_prices.resample('D').last().ffill())\n",
    "    fracDiff = FractionalDifferentiator()\n",
    "    if adf_result[1] > 0.05: \n",
    "        frac_diff_log_price = fracDiff.FitTransform(log_prices)\n",
    "    else: \n",
    "        frac_diff_log_price = log_prices\n",
    "    return frac_diff_log_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>returns</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>sma_20</th>\n",
       "      <th>sma_100</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>ema_100</th>\n",
       "      <th>roc_10</th>\n",
       "      <th>roc_20</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_13</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>frac_diff_log</th>\n",
       "      <th>volat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>1.07648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073418</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.079063</td>\n",
       "      <td>1.074019</td>\n",
       "      <td>1.07272</td>\n",
       "      <td>1.078071</td>\n",
       "      <td>0.672409</td>\n",
       "      <td>0.909278</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0665</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close  returns    sma_10   sma_20   sma_100    ema_10   ema_20  \\\n",
       "Date                                                                           \n",
       "2024-05-07  1.07648      NaN  1.073418  1.07058  1.079063  1.074019  1.07272   \n",
       "\n",
       "             ema_100    roc_10    roc_20  ...   lag_7    lag_8    lag_9  \\\n",
       "Date                                      ...                             \n",
       "2024-05-07  1.078071  0.672409  0.909278  ...  1.0665  1.07136  1.07058   \n",
       "\n",
       "             lag_10   lag_11   lag_12   lag_13   lag_14  frac_diff_log  \\\n",
       "Date                                                                     \n",
       "2024-05-07  1.06929  1.06929  1.07256  1.06989  1.07013       0.017176   \n",
       "\n",
       "               volat  \n",
       "Date                  \n",
       "2024-05-07  0.004088  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['frac_diff_log'] = get_fracdiff_log_price(df['close'])\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily volatility using EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_volat_w_log_returns(\n",
    "    close: pd.Series,\n",
    "    span: int = 100\n",
    ") -> pd.Series:\n",
    "    \"\"\" create daily volatility series using ewm \"\"\"\n",
    "\n",
    "    df = close.index.searchsorted(close.index - pd.Timedelta(days=1))        \n",
    "    df = df[df > 0]\n",
    "    df = pd.Series(close.index[df - 1], index = close.index[close.shape[0] - df.shape[0]:])\n",
    "    returns = np.log(close.loc[df.index] / close.loc[df.values].values)\n",
    "    stds = returns.ewm(span=span).std().rename(\"std\")\n",
    "\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>returns</th>\n",
       "      <th>sma_10</th>\n",
       "      <th>sma_20</th>\n",
       "      <th>sma_100</th>\n",
       "      <th>ema_10</th>\n",
       "      <th>ema_20</th>\n",
       "      <th>ema_100</th>\n",
       "      <th>roc_10</th>\n",
       "      <th>roc_20</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_13</th>\n",
       "      <th>lag_14</th>\n",
       "      <th>frac_diff_log</th>\n",
       "      <th>volat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>1.07648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073418</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.079063</td>\n",
       "      <td>1.074019</td>\n",
       "      <td>1.07272</td>\n",
       "      <td>1.078071</td>\n",
       "      <td>0.672409</td>\n",
       "      <td>0.909278</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0665</td>\n",
       "      <td>1.07136</td>\n",
       "      <td>1.07058</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.06929</td>\n",
       "      <td>1.07256</td>\n",
       "      <td>1.06989</td>\n",
       "      <td>1.07013</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close  returns    sma_10   sma_20   sma_100    ema_10   ema_20  \\\n",
       "Date                                                                           \n",
       "2024-05-07  1.07648      NaN  1.073418  1.07058  1.079063  1.074019  1.07272   \n",
       "\n",
       "             ema_100    roc_10    roc_20  ...   lag_7    lag_8    lag_9  \\\n",
       "Date                                      ...                             \n",
       "2024-05-07  1.078071  0.672409  0.909278  ...  1.0665  1.07136  1.07058   \n",
       "\n",
       "             lag_10   lag_11   lag_12   lag_13   lag_14  frac_diff_log  \\\n",
       "Date                                                                     \n",
       "2024-05-07  1.06929  1.06929  1.07256  1.06989  1.07013       0.017176   \n",
       "\n",
       "               volat  \n",
       "Date                  \n",
       "2024-05-07  0.004088  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['volat'] = get_daily_volat_w_log_returns(df['close'], 100)\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main model: Momentum strat using EWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_position(\n",
    "#     prices: pd.Series,\n",
    "#     fast_window: int,\n",
    "#     slow_window: int,\n",
    "#     mean_reversion: bool = False,\n",
    "# ) -> pd.Series:\n",
    "#     \"\"\" create position series based on moving averages \"\"\"\n",
    "#     if fast_window >= slow_window:\n",
    "#         raise ValueError(\"The fast window should be smaller than the slow window.\")\n",
    "\n",
    "#     fast_moving_average = prices.ewm(span=fast_window, adjust=False, min_periods=1).mean()\n",
    "#     slow_moving_average = prices.ewm(span=slow_window, adjust=False, min_periods=1).mean()\n",
    "\n",
    "#     if mean_reversion:\n",
    "#         return (fast_moving_average < slow_moving_average).astype(int) * 2 - 1\n",
    "#     else:\n",
    "#         return (fast_moving_average >= slow_moving_average).astype(int) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(\n",
    "    prices: pd.Series,\n",
    ") -> pd.Series:\n",
    "    pos = []\n",
    "    for i in range(len(prices)):\n",
    "        if prices.iloc[i] < prices.iloc[i-1]:\n",
    "            pos.append(1)\n",
    "        elif prices.iloc[i] > prices.iloc[i-1]:\n",
    "            pos.append(-1)\n",
    "        else:\n",
    "            pos.append(0)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "position\n",
       " 1    2253\n",
       "-1    2211\n",
       " 0     775\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['position'] = get_position(prices_daily['EURUSD'])\n",
    "df.position.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_barrier(\n",
    "    close: pd.Series,\n",
    "    time_events: pd.DatetimeIndex,\n",
    "    number_days: int) -> pd.Series:\n",
    "    \"\"\" create vertical barrier series: the exit timestamp after a certain number of days \"\"\"\n",
    "    timestamp_array = close.index.searchsorted(time_events + pd.Timedelta(days=number_days))\n",
    "    timestamp_array = timestamp_array[timestamp_array < close.shape[0]]\n",
    "    timestamp_array = pd.Series(close.index[timestamp_array], index=time_events[:timestamp_array.shape[0]])\n",
    "    return timestamp_array \n",
    "\n",
    "def main_labelling(\n",
    "    df: pd.DataFrame,\n",
    "    num_days: int # holding days / vertical barriers\n",
    ") -> pd.DataFrame:\n",
    "    end_times = vertical_barrier(df['close'], df.index, num_days).dropna()\n",
    "    df['vert_bars'] = end_times.reindex(df.index)\n",
    "    df['end_time'] = df['vert_bars']\n",
    "    \n",
    "    df['end_close'] = df['vert_bars'].map(df['close'])\n",
    "\n",
    "    df['profit'] = df['end_close'] / df['close'] - 1\n",
    "    df['profit'] *= df['position']\n",
    "    df['outcome'] = np.sign(df['profit'])\n",
    "    df.loc[df['profit'] <= 0, 'outcome'] = 0\n",
    "    df['outcome'].reindex(df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>pnl</th>\n",
       "      <th>vert_bars</th>\n",
       "      <th>end_time</th>\n",
       "      <th>end_close</th>\n",
       "      <th>profit</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-04-13</td>\n",
       "      <td>2010-04-13</td>\n",
       "      <td>1.36414</td>\n",
       "      <td>0.044084</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.004225</td>\n",
       "      <td>2010-04-14</td>\n",
       "      <td>2010-04-14</td>\n",
       "      <td>1.36511</td>\n",
       "      <td>0.053250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>1.35388</td>\n",
       "      <td>-0.057679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>1.35017</td>\n",
       "      <td>0.063929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002234</td>\n",
       "      <td>2010-04-17</td>\n",
       "      <td>2010-04-17</td>\n",
       "      <td>1.35017</td>\n",
       "      <td>-0.056597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-04</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-05</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-07</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            position       pnl  vert_bars   end_time  end_close    profit  \\\n",
       "Date                                                                        \n",
       "2010-01-03        -1       NaN 2010-04-13 2010-04-13    1.36414  0.044084   \n",
       "2010-01-04        -1 -0.004225 2010-04-14 2010-04-14    1.36511  0.053250   \n",
       "2010-01-05         1  0.013178 2010-04-15 2010-04-15    1.35388 -0.057679   \n",
       "2010-01-06        -1 -0.007845 2010-04-16 2010-04-16    1.35017  0.063929   \n",
       "2010-01-07         1 -0.002234 2010-04-17 2010-04-17    1.35017 -0.056597   \n",
       "...              ...       ...        ...        ...        ...       ...   \n",
       "2024-05-03        -1       NaN        NaT        NaT        NaN       NaN   \n",
       "2024-05-04         0       NaN        NaT        NaT        NaN       NaN   \n",
       "2024-05-05         1       NaN        NaT        NaT        NaN       NaN   \n",
       "2024-05-06        -1       NaN        NaT        NaT        NaN       NaN   \n",
       "2024-05-07         1       NaN        NaT        NaT        NaN       NaN   \n",
       "\n",
       "            outcome  \n",
       "Date                 \n",
       "2010-01-03      1.0  \n",
       "2010-01-04      1.0  \n",
       "2010-01-05      0.0  \n",
       "2010-01-06      1.0  \n",
       "2010-01-07      0.0  \n",
       "...             ...  \n",
       "2024-05-03      NaN  \n",
       "2024-05-04      NaN  \n",
       "2024-05-05      NaN  \n",
       "2024-05-06      NaN  \n",
       "2024-05-07      NaN  \n",
       "\n",
       "[5239 rows x 7 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = main_labelling(df, 100)\n",
    "df.iloc[:, -7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `outcome` as the direction of return (1 for gain, 0 for neutral or loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "close              0\n",
       "returns           14\n",
       "sma_10             9\n",
       "sma_20            19\n",
       "sma_100           99\n",
       "ema_10             9\n",
       "ema_20            19\n",
       "ema_100           99\n",
       "roc_10             0\n",
       "roc_20             0\n",
       "roc_100            0\n",
       "bb_upper          19\n",
       "bb_middle         19\n",
       "bb_lower          19\n",
       "rsi_10             0\n",
       "rsi_20             0\n",
       "rsi_100            0\n",
       "log_macd_hist      0\n",
       "log_dpo           19\n",
       "gmm_state_0       14\n",
       "gmm_state_1       14\n",
       "lag_1              1\n",
       "lag_2              2\n",
       "lag_3              3\n",
       "lag_4              4\n",
       "lag_5              5\n",
       "lag_6              6\n",
       "lag_7              7\n",
       "lag_8              8\n",
       "lag_9              9\n",
       "lag_10            10\n",
       "lag_11            11\n",
       "lag_12            12\n",
       "lag_13            13\n",
       "lag_14            14\n",
       "frac_diff_log    486\n",
       "volat              3\n",
       "position           0\n",
       "pnl               15\n",
       "vert_bars        100\n",
       "end_time         100\n",
       "end_close        100\n",
       "profit           100\n",
       "outcome          100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0    2917\n",
       "1.0    2222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model: Triple barrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Position (side)**: In layman's term, all positions are held for like 100 units of time (aka until it hits vertical barrier). But for events that are considered significant (according to CUMSUM filter), it's held until we hit profit taking or stop loss, or until it expires at the vertical barrier.\n",
    "\n",
    "**Outcome (labels)**: Profitable = assigned 1, neutral / loss = assigned 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUMSUM: identify significant events to apply a secondary meta labelling level on top of main model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusum_filter_events_dynamic_threshold(\n",
    "    prices: pd.Series,\n",
    "    threshold: pd.Series,\n",
    ") -> pd.DatetimeIndex:\n",
    "    \"\"\" identify events that are 'too' volatile based on \n",
    "    dynamic threshold using cumsum filter \"\"\"\n",
    "    events, shift_positive, shift_negative = [], 0, 0\n",
    "    price_delta = prices.diff().dropna()\n",
    "    thresholds = threshold.copy()\n",
    "    price_delta, thresholds = price_delta.align(thresholds, join=\"inner\", copy=False)\n",
    "\n",
    "    for (index, value), threshold_ in zip(price_delta.to_dict().items(), thresholds.to_dict().values()):\n",
    "        shift_positive = max(0, shift_positive + value)\n",
    "        shift_negative = min(0, shift_negative + value)\n",
    "\n",
    "        if shift_negative < -threshold_:\n",
    "            shift_negative = 0\n",
    "            events.append(index)\n",
    "\n",
    "        elif shift_positive > threshold_:\n",
    "            shift_positive = 0\n",
    "            events.append(index)\n",
    "\n",
    "    return pd.DatetimeIndex(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRIPLE BARRIERS: for the identified events, update the new exit time - instead of vertical barriers its whatever barrier hit first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_barrier_events(\n",
    "    df: pd.DataFrame,\n",
    "    ptsl: list[float], \n",
    "    filter_threshold: float\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # significent events\n",
    "    sig_events = cusum_filter_events_dynamic_threshold(np.log(df['close']), filter_threshold * df['volat'])\n",
    "    sig_df = df.loc[sig_events, ['volat', 'position', 'close', 'vert_bars']]\n",
    "\n",
    "    # ptsl\n",
    "    profit_loss = ptsl[:2] \n",
    "    if ptsl[0] > 0:\n",
    "        pt = ptsl[0] * sig_df['volat']\n",
    "    else:\n",
    "        pt = pd.Series(index = sig_df.index)\n",
    "    if ptsl[1] > 0:\n",
    "        sl = -ptsl[1] * sig_df['volat']\n",
    "    else: \n",
    "        sl = pd.Series(index = sig_df.index)\n",
    "\n",
    "    # return time barriers hit\n",
    "    for start, end in sig_df['vert_bars'].items():\n",
    "        price_segment = df['close'][start:end]\n",
    "        # find log return of price slice\n",
    "        returns = np.log(price_segment / price_segment.iloc[0]) * sig_df.at[start, 'position']\n",
    "        # find the first index where the returns are below the stop-loss level sl[start]\n",
    "        sig_df.loc[start, 'stop_loss'] = returns[returns < sl[start]].index.min()\n",
    "        sig_df.loc[start, 'profit_taking'] = returns[returns > pt[start]].index.min()\n",
    "        \n",
    "    sig_df.dropna()\n",
    "    sig_df['end_time'] = sig_df[['stop_loss', 'profit_taking', 'vert_bars']].min(axis=1)\n",
    "    sig_df.dropna(subset=['end_time'], inplace=True)\n",
    "    return sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volat</th>\n",
       "      <th>position</th>\n",
       "      <th>close</th>\n",
       "      <th>vert_bars</th>\n",
       "      <th>stop_loss</th>\n",
       "      <th>profit_taking</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 23:00:00</th>\n",
       "      <td>0.001350</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.44189</td>\n",
       "      <td>2010-04-14 23:00:00</td>\n",
       "      <td>2010-01-05 03:00:00</td>\n",
       "      <td>2010-01-05 16:00:00</td>\n",
       "      <td>2010-01-05 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05 03:00:00</th>\n",
       "      <td>0.001611</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.44635</td>\n",
       "      <td>2010-04-15 03:00:00</td>\n",
       "      <td>2010-01-11 00:00:00</td>\n",
       "      <td>2010-01-05 06:00:00</td>\n",
       "      <td>2010-01-05 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05 06:00:00</th>\n",
       "      <td>0.001744</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.44162</td>\n",
       "      <td>2010-04-15 06:00:00</td>\n",
       "      <td>2010-01-10 21:00:00</td>\n",
       "      <td>2010-01-05 16:00:00</td>\n",
       "      <td>2010-01-05 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07 09:00:00</th>\n",
       "      <td>0.004749</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.43346</td>\n",
       "      <td>2010-04-17 09:00:00</td>\n",
       "      <td>2010-01-08 11:00:00</td>\n",
       "      <td>2010-01-19 23:00:00</td>\n",
       "      <td>2010-01-08 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08 11:00:00</th>\n",
       "      <td>0.004635</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.44039</td>\n",
       "      <td>2010-04-18 11:00:00</td>\n",
       "      <td>2010-01-10 22:00:00</td>\n",
       "      <td>2010-01-19 09:00:00</td>\n",
       "      <td>2010-01-10 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 14:00:00</th>\n",
       "      <td>0.001819</td>\n",
       "      <td>1</td>\n",
       "      <td>1.06899</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-04-30 20:00:00</td>\n",
       "      <td>2024-05-01 18:00:00</td>\n",
       "      <td>2024-04-30 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 18:00:00</th>\n",
       "      <td>0.002757</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07270</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-05-01 19:00:00</td>\n",
       "      <td>2024-05-03 12:00:00</td>\n",
       "      <td>2024-05-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03 08:00:00</th>\n",
       "      <td>0.003026</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07414</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-05-03 12:00:00</td>\n",
       "      <td>2024-05-03 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03 12:00:00</th>\n",
       "      <td>0.003154</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07926</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-05-05 23:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2024-05-05 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-07 02:00:00</th>\n",
       "      <td>0.001835</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.07626</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4207 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        volat  position    close           vert_bars  \\\n",
       "2010-01-04 23:00:00  0.001350        -1  1.44189 2010-04-14 23:00:00   \n",
       "2010-01-05 03:00:00  0.001611        -1  1.44635 2010-04-15 03:00:00   \n",
       "2010-01-05 06:00:00  0.001744        -1  1.44162 2010-04-15 06:00:00   \n",
       "2010-01-07 09:00:00  0.004749        -1  1.43346 2010-04-17 09:00:00   \n",
       "2010-01-08 11:00:00  0.004635        -1  1.44039 2010-04-18 11:00:00   \n",
       "...                       ...       ...      ...                 ...   \n",
       "2024-04-30 14:00:00  0.001819         1  1.06899                 NaT   \n",
       "2024-05-01 18:00:00  0.002757         1  1.07270                 NaT   \n",
       "2024-05-03 08:00:00  0.003026         1  1.07414                 NaT   \n",
       "2024-05-03 12:00:00  0.003154         1  1.07926                 NaT   \n",
       "2024-05-07 02:00:00  0.001835        -1  1.07626                 NaT   \n",
       "\n",
       "                              stop_loss       profit_taking  \\\n",
       "2010-01-04 23:00:00 2010-01-05 03:00:00 2010-01-05 16:00:00   \n",
       "2010-01-05 03:00:00 2010-01-11 00:00:00 2010-01-05 06:00:00   \n",
       "2010-01-05 06:00:00 2010-01-10 21:00:00 2010-01-05 16:00:00   \n",
       "2010-01-07 09:00:00 2010-01-08 11:00:00 2010-01-19 23:00:00   \n",
       "2010-01-08 11:00:00 2010-01-10 22:00:00 2010-01-19 09:00:00   \n",
       "...                                 ...                 ...   \n",
       "2024-04-30 14:00:00 2024-04-30 20:00:00 2024-05-01 18:00:00   \n",
       "2024-05-01 18:00:00 2024-05-01 19:00:00 2024-05-03 12:00:00   \n",
       "2024-05-03 08:00:00                 NaT 2024-05-03 12:00:00   \n",
       "2024-05-03 12:00:00 2024-05-05 23:00:00                 NaT   \n",
       "2024-05-07 02:00:00                 NaT                 NaT   \n",
       "\n",
       "                               end_time  \n",
       "2010-01-04 23:00:00 2010-01-05 03:00:00  \n",
       "2010-01-05 03:00:00 2010-01-05 06:00:00  \n",
       "2010-01-05 06:00:00 2010-01-05 16:00:00  \n",
       "2010-01-07 09:00:00 2010-01-08 11:00:00  \n",
       "2010-01-08 11:00:00 2010-01-10 22:00:00  \n",
       "...                                 ...  \n",
       "2024-04-30 14:00:00 2024-04-30 20:00:00  \n",
       "2024-05-01 18:00:00 2024-05-01 19:00:00  \n",
       "2024-05-03 08:00:00 2024-05-03 12:00:00  \n",
       "2024-05-03 12:00:00 2024-05-05 23:00:00  \n",
       "2024-05-07 02:00:00                 NaT  \n",
       "\n",
       "[4207 rows x 7 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_df = meta_events(df, ptsl = [1.5, 1], filter_threshold = 1.5)\n",
    "sig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volat              0\n",
       "position           0\n",
       "close              0\n",
       "vert_bars         80\n",
       "stop_loss        365\n",
       "profit_taking    468\n",
       "end_time           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**META LABELLING: find the new close/profit etc. & overlay the meta results on top of the main results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = df.copy(deep = True)\n",
    "testy.loc[sig_df.index, 'end_time'] = sig_df['end_time']\n",
    "testy\n",
    "testy['end_close'] = testy['vert_bars'].map(testy['close'])\n",
    "\n",
    "testy['profit'] = testy['end_close'] / testy['close'] - 1\n",
    "testy['profit'] *= testy['position']\n",
    "testy['outcome'] = np.sign(testy['profit'])\n",
    "testy.loc[testy['profit'] <= 0, 'outcome'] = 0\n",
    "testy['outcome'].reindex(testy.index)\n",
    "testy.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0    61976\n",
       "1.0    60919\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0    61995\n",
       "1.0    61308\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_labelling(\n",
    "    df: pd.DataFrame,\n",
    "    ptsl: list[float], \n",
    "    filter_threshold: float    \n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    sig_df = triple_barrier_events(df, ptsl, filter_threshold)\n",
    "    df.join(sig_df, how='left')\n",
    "\n",
    "    sig_df.dropna(subset=['end_time'])\n",
    "    sig_df['profit'] = \n",
    "\n",
    "    meta_labels = pd.Series(index = df.index)\n",
    "    for idx, (start, end) in triple_barrier_events['end_time'].iteritems():\n",
    "        meta_labels.loc[start:end] = triple_barrier_events.loc[idx, 'outcome']\n",
    "    return meta_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusum_filter_events_dynamic_threshold(\n",
    "    prices: pd.Series,\n",
    "    threshold: pd.Series\n",
    ") -> pd.DatetimeIndex:\n",
    "    \"\"\" identify events that are 'too' volatile based on \n",
    "    dynamic threshold using cumsum filter \"\"\"\n",
    "    time_events, shift_positive, shift_negative = [], 0, 0\n",
    "    price_delta = prices.diff().dropna()\n",
    "    thresholds = threshold.copy()\n",
    "    price_delta, thresholds = price_delta.align(thresholds, join=\"inner\", copy=False)\n",
    "\n",
    "    for (index, value), threshold_ in zip(price_delta.to_dict().items(), thresholds.to_dict().values()):\n",
    "        shift_positive = max(0, shift_positive + value)\n",
    "        shift_negative = min(0, shift_negative + value)\n",
    "\n",
    "        if shift_negative < -threshold_:\n",
    "            shift_negative = 0\n",
    "            time_events.append(index)\n",
    "\n",
    "        elif shift_positive > threshold_:\n",
    "            shift_positive = 0\n",
    "            time_events.append(index)\n",
    "\n",
    "    return pd.DatetimeIndex(time_events)\n",
    "\n",
    "def triple_barrier(\n",
    "    close: pd.Series,\n",
    "    events: pd.DataFrame,\n",
    "    profit_taking_stop_loss: list[float, float],\n",
    "    molecule: list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" identify triple barriers: pt, sl, vertical barrier \"\"\"\n",
    "    events_filtered = events.loc[molecule]\n",
    "    output = events_filtered[['End Time']].copy(deep=True)\n",
    "\n",
    "    if profit_taking_stop_loss[0] > 0:\n",
    "        profit_taking = profit_taking_stop_loss[0] * events_filtered['Base Width']\n",
    "    else:\n",
    "        profit_taking = pd.Series(index=events.index)\n",
    "\n",
    "    if profit_taking_stop_loss[1] > 0:\n",
    "        stop_loss = -profit_taking_stop_loss[1] * events_filtered['Base Width']\n",
    "    else:\n",
    "        stop_loss = pd.Series(index=events.index)\n",
    "\n",
    "    for location, timestamp in events_filtered['End Time'].fillna(close.index[-1]).items():\n",
    "        df = close[location:timestamp]\n",
    "        df = np.log(df / close[location]) * events_filtered.at[location, 'position']\n",
    "        output.loc[location, 'stop_loss'] = df[df < stop_loss[location]].index.min()\n",
    "        output.loc[location, 'profit_taking'] = df[df > profit_taking[location]].index.min()\n",
    "    return output\n",
    "\n",
    "def meta_events(\n",
    "    close: pd.Series,\n",
    "    time_events: pd.DatetimeIndex,\n",
    "    ptsl: list, \n",
    "    target: pd.Series,\n",
    "    return_min: float,\n",
    "    num_threads: int,\n",
    "    timestamp: pd.Series = False,\n",
    "    side: pd.Series = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" apply the triple barriers to the identified volatile events\n",
    "    (exit price recorded at whatever barrier it hits first out of the 3) \"\"\"\n",
    "    target = target.loc[time_events]\n",
    "    target = target[target > return_min]\n",
    "    if timestamp is False:\n",
    "        timestamp = pd.Series(pd.NaT, index=time_events)\n",
    "\n",
    "    if side is None:\n",
    "        side_position, profit_loss = pd.Series(1., index=target.index), [ptsl[0], ptsl[0]]\n",
    "    else:\n",
    "        side_position, profit_loss = side.loc[target.index], ptsl[:2]\n",
    "\n",
    "    events = pd.concat({'End Time': timestamp, 'Base Width': target, 'position': side_position}, axis=1).dropna(subset=['Base Width'])\n",
    "    if num_threads > 1:\n",
    "        with ProcessPoolExecutor(num_threads) as executor:\n",
    "            df0 = list(executor.map(triple_barrier, [close] * num_threads, [events] * num_threads, [profit_loss] * num_threads, list(np.array_split(time_events, num_threads))))\n",
    "    else:\n",
    "        df0 = list(map(triple_barrier, [close] * num_threads, [events] * num_threads, [profit_loss] * num_threads, list(np.array_split(time_events, num_threads))))\n",
    "    df0 = pd.concat(df0, axis=0)\n",
    "    events['End Time'] = df0.dropna(how='all').min(axis=1)\n",
    "\n",
    "    if side is None:\n",
    "        events = events.drop('position', axis=1)\n",
    "    return events\n",
    "\n",
    "def meta_labeling(events: pd.DataFrame, close: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\" create labels given triple barriers\n",
    "    (instead of constant time horizon like in normal labelling) \"\"\"\n",
    "    events_filtered = events.dropna(subset=['End Time'])\n",
    "    all_dates = events_filtered.index.union(events_filtered['End Time'].values).drop_duplicates()\n",
    "    close_filtered = close.reindex(all_dates, method='bfill')\n",
    "    out = pd.DataFrame(index = events_filtered.index)\n",
    "    out['End Time'] = events['End Time']\n",
    "    out['profit'] = close_filtered.loc[events_filtered['End Time'].values].values / close_filtered.loc[events_filtered.index] - 1\n",
    "    if 'position' in events_filtered:\n",
    "        out['profit'] *= events_filtered['position']\n",
    "    out['outcome'] = np.sign(out['profit'])\n",
    "    if 'position' in events_filtered:\n",
    "        out.loc[out['profit'] <= 0, 'outcome'] = 0\n",
    "        out['position'] = events_filtered['position']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side = position (long = 1, short = -1)\n",
    "\n",
    "Label = direction of return (profitable (+1), unprofitable or neutral (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome_w_metalabels\n",
       "1.0    61721\n",
       "0.0    61174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['outcome_w_metalabels'] = df['outcome'].copy()\n",
    "df['outcome_w_metalabels'].update(secondary['outcome'])\n",
    "df.dropna(inplace = True)\n",
    "df.outcome_w_metalabels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    " \n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Inquiry question: DOES META LABELLING ACTUALLY INCREASE SIGNAL EFFICACY?**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It went from: 36564 ones to 37515 ones (IS)\n",
    "\n",
    "To evaluate the effcacy of meta-labeling we look at a models performance metrics between the validation set and the out-of-sample test set. \n",
    "\n",
    "-> RandomForestClassifier\n",
    "\n",
    "This allows us to draw conclusions about the models ability to generalize. In particular we need to look at the recall, precision, F1 score, and accuracy. The reason why we dont compare the strategies performance metrics (annualized returns, sharpe ratio, and drawdowns) is because the two data sets are from very di erent time periods. For example, if the validation set has a much higher volatility than the test set, then the validation returns will be larger. This will prevent like for like comparison. We can however compare strategy metrics if they are both from the same time period. We do provide performance metrics on the test data. Additionally we add a performance tear sheet, and see that meta-labeling results in better strategy metrics but it should be noted that we have yet to add a bet sizing component to the strategy. Additionally the two strategies we test are based on technical analysis and they dont provide the best signals. A primary model with better predictive power would provide further insigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome_w_metalabels\n",
       "1.0    61721\n",
       "0.0    61174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['outcome_w_metalabels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome\n",
       "0.0    61976\n",
       "1.0    60919\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = df.drop(columns=[\\'position\\', \\'outcome\\', \\'outcome_w_metalabels\\'])\\ntarget_outcome = df[\\'outcome\\']\\ntarget_meta_outcome = df[\\'outcome_w_metalabels\\']\\n\\nX_train, X_test, y_train, y_test = train_test_split(features, target_outcome, test_size=0.2, random_state=42)\\nX_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(features, target_meta_outcome, test_size=0.2, random_state=42)\\n\\nprimary_model = RandomForestClassifier(random_state=42)\\nprimary_model.fit(X_train, y_train)\\nprimary_predictions = primary_model.predict(X_test)\\n\\nX_train_meta[\\'primary_predictions\\'] = primary_model.predict(X_train)\\nX_test_meta[\\'primary_predictions\\'] = primary_predictions\\n\\nmeta_model = RandomForestClassifier(random_state=42)\\nmeta_model.fit(X_train_meta, y_train_meta)\\nmeta_predictions = meta_model.predict(X_test_meta)\\n\\nprimary_accuracy = accuracy_score(y_test, primary_predictions)\\nprimary_mcc = matthews_corrcoef(y_test, primary_predictions)\\nprimary_report = classification_report(y_test, primary_predictions)\\nprimary_conf_matrix = confusion_matrix(y_test, primary_predictions)\\nprimary_fpr, primary_tpr, _ = roc_curve(y_test, primary_predictions)\\nprimary_roc_auc = auc(primary_fpr, primary_tpr)\\nprimary_precision, primary_recall, _ = precision_recall_curve(y_test, primary_predictions)\\nprimary_pr_auc = auc(primary_recall, primary_precision)\\n\\nmeta_accuracy = accuracy_score(y_test_meta, meta_predictions)\\nmeta_mcc = matthews_corrcoef(y_test_meta, meta_predictions)\\nmeta_report = classification_report(y_test_meta, meta_predictions)\\nmeta_conf_matrix = confusion_matrix(y_test_meta, meta_predictions)\\nmeta_fpr, meta_tpr, _ = roc_curve(y_test_meta, meta_predictions)\\nmeta_roc_auc = auc(meta_fpr, meta_tpr)\\nmeta_precision, meta_recall, _ = precision_recall_curve(y_test_meta, meta_predictions)\\nmeta_pr_auc = auc(meta_recall, meta_precision)\\n\\nprint(\"Primary model:\")\\nprint(f\"Accuracy: {primary_accuracy}\")\\nprint(f\"MCC: {primary_mcc}\")\\nprint(f\"ROC AUC: {primary_roc_auc}\")\\nprint(f\"Precision-recall AUC: {primary_pr_auc}\")\\nprint(primary_report)\\nprint(primary_conf_matrix)\\n\\nprint(\"\\nMeta model:\")\\nprint(f\"Accuracy: {meta_accuracy}\")\\nprint(f\"MCC: {meta_mcc}\")\\nprint(f\"ROC AUC: {meta_roc_auc}\")\\nprint(f\"Precision-recall AUC: {meta_pr_auc}\")\\nprint(meta_report)\\nprint(meta_conf_matrix)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "features = df.drop(columns=['position', 'outcome', 'outcome_w_metalabels'])\n",
    "target_outcome = df['outcome']\n",
    "target_meta_outcome = df['outcome_w_metalabels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_outcome, test_size=0.2, random_state=42)\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(features, target_meta_outcome, test_size=0.2, random_state=42)\n",
    "\n",
    "primary_model = RandomForestClassifier(random_state=42)\n",
    "primary_model.fit(X_train, y_train)\n",
    "primary_predictions = primary_model.predict(X_test)\n",
    "\n",
    "X_train_meta['primary_predictions'] = primary_model.predict(X_train)\n",
    "X_test_meta['primary_predictions'] = primary_predictions\n",
    "\n",
    "meta_model = RandomForestClassifier(random_state=42)\n",
    "meta_model.fit(X_train_meta, y_train_meta)\n",
    "meta_predictions = meta_model.predict(X_test_meta)\n",
    "\n",
    "primary_accuracy = accuracy_score(y_test, primary_predictions)\n",
    "primary_mcc = matthews_corrcoef(y_test, primary_predictions)\n",
    "primary_report = classification_report(y_test, primary_predictions)\n",
    "primary_conf_matrix = confusion_matrix(y_test, primary_predictions)\n",
    "primary_fpr, primary_tpr, _ = roc_curve(y_test, primary_predictions)\n",
    "primary_roc_auc = auc(primary_fpr, primary_tpr)\n",
    "primary_precision, primary_recall, _ = precision_recall_curve(y_test, primary_predictions)\n",
    "primary_pr_auc = auc(primary_recall, primary_precision)\n",
    "\n",
    "meta_accuracy = accuracy_score(y_test_meta, meta_predictions)\n",
    "meta_mcc = matthews_corrcoef(y_test_meta, meta_predictions)\n",
    "meta_report = classification_report(y_test_meta, meta_predictions)\n",
    "meta_conf_matrix = confusion_matrix(y_test_meta, meta_predictions)\n",
    "meta_fpr, meta_tpr, _ = roc_curve(y_test_meta, meta_predictions)\n",
    "meta_roc_auc = auc(meta_fpr, meta_tpr)\n",
    "meta_precision, meta_recall, _ = precision_recall_curve(y_test_meta, meta_predictions)\n",
    "meta_pr_auc = auc(meta_recall, meta_precision)\n",
    "\n",
    "print(\"Primary model:\")\n",
    "print(f\"Accuracy: {primary_accuracy}\")\n",
    "print(f\"MCC: {primary_mcc}\")\n",
    "print(f\"ROC AUC: {primary_roc_auc}\")\n",
    "print(f\"Precision-recall AUC: {primary_pr_auc}\")\n",
    "print(primary_report)\n",
    "print(primary_conf_matrix)\n",
    "\n",
    "print(\"\\nMeta model:\")\n",
    "print(f\"Accuracy: {meta_accuracy}\")\n",
    "print(f\"MCC: {meta_mcc}\")\n",
    "print(f\"ROC AUC: {meta_roc_auc}\")\n",
    "print(f\"Precision-recall AUC: {meta_pr_auc}\")\n",
    "print(meta_report)\n",
    "print(meta_conf_matrix)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primary model performs slightly better across most metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    " \n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**MODEL FITTING**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m target_meta \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome_w_metalabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 5\u001b[0m features_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m X_train_meta, X_test_meta, y_train_meta, y_test_meta \u001b[38;5;241m=\u001b[39m train_test_split(features_scaled, target_meta, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m404\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:887\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    883\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    884\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    885\u001b[0m )\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 887\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    890\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)"
     ]
    }
   ],
   "source": [
    "features = df.drop(columns=['position', 'outcome', 'outcome_w_metalabels'])\n",
    "target_meta = df['outcome_w_metalabels']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X_train_meta, X_test_meta, y_train_meta, y_test_meta = train_test_split(features_scaled, target_meta, test_size=0.2, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio(returns: np.ndarray, risk_free_rate: float = 0.0) -> float:\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    std = np.std(excess_returns)\n",
    "    if std != 0:\n",
    "        return ((excess_returns.mean() / std) * np.sqrt(252*24))  # to annualise\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def max_drawdown(returns: np.ndarray) -> float:\n",
    "    cumulative_returns = np.cumprod(1 + returns) - 1\n",
    "    drawdowns = cumulative_returns - np.maximum.accumulate(cumulative_returns)\n",
    "    return np.min(drawdowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will delete later: split data by half for a quick trial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcut = df.iloc[int(len(df)/2):, :]\n",
    "features = dfcut.drop(columns=['position', 'outcome', 'outcome_w_metalabels'])\n",
    "target_meta = dfcut['outcome_w_metalabels']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.421-b09, mixed mode)\n",
      "  Starting server from C:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Kalulu\\AppData\\Local\\Temp\\tmpkzez5bna\n",
      "  JVM stdout: C:\\Users\\Kalulu\\AppData\\Local\\Temp\\tmpkzez5bna\\h2o_Kalulu_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Kalulu\\AppData\\Local\\Temp\\tmpkzez5bna\\h2o_Kalulu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Bangkok</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>24 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Kalulu_1w5x3p</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.764 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         05 secs\n",
       "H2O_cluster_timezone:       Asia/Bangkok\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.4\n",
       "H2O_cluster_version_age:    24 days\n",
       "H2O_cluster_name:           H2O_from_python_Kalulu_1w5x3p\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.764 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.0 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Train/test length: (40470, 10071)\n",
      "AutoML progress: |\n",
      "13:47:08.644: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "h2o.init(max_mem_size = \"2G\")\n",
    "\n",
    "combined_df = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "combined_df['outcome_w_metalabels'] = target_meta.values\n",
    "h2o_df = h2o.H2OFrame(combined_df)\n",
    "train, test = h2o_df.split_frame(ratios=[.8], seed=1234)\n",
    "x = train.columns[:-1]\n",
    "y = 'outcome_w_metalabels'\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "print(f'Train/test length: {len(train), len(test)}')\n",
    "\n",
    "aml = H2OAutoML(max_models=2, seed=404)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "lb = h2o.automl.get_leaderboard(aml, extra_columns=\"ALL\")\n",
    "lb_df = lb.as_data_frame()\n",
    "\n",
    "all_preds = {}\n",
    "for model_id in lb_df['model_id']:\n",
    "    model = h2o.get_model(model_id)\n",
    "    preds = model.predict(test)\n",
    "    all_preds[model_id] = preds.as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h20 xgboost is not available on window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lb_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[284], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlb_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lb_df' is not defined"
     ]
    }
   ],
   "source": [
    "lb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict\n",
       "1    5368\n",
       "0    4703\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_results = all_preds['GBM_1_AutoML_1_20240803_134708']\n",
    "gbm_results['predict'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">    close</th><th style=\"text-align: right;\">   returns</th><th style=\"text-align: right;\">   sma_10</th><th style=\"text-align: right;\">   sma_20</th><th style=\"text-align: right;\">  sma_100</th><th style=\"text-align: right;\">   ema_10</th><th style=\"text-align: right;\">   ema_20</th><th style=\"text-align: right;\">  ema_100</th><th style=\"text-align: right;\">    z-score</th><th style=\"text-align: right;\">   roc_10</th><th style=\"text-align: right;\">   roc_20</th><th style=\"text-align: right;\">   roc_100</th><th style=\"text-align: right;\">  bb_upper</th><th style=\"text-align: right;\">  bb_middle</th><th style=\"text-align: right;\">  bb_lower</th><th style=\"text-align: right;\">   rsi_10</th><th style=\"text-align: right;\">   rsi_20</th><th style=\"text-align: right;\">  rsi_100</th><th style=\"text-align: right;\">  log_macd_hist</th><th style=\"text-align: right;\">  log_dpo</th><th style=\"text-align: right;\">  gmm_state_0</th><th style=\"text-align: right;\">  gmm_state_1</th><th style=\"text-align: right;\">    lag_1</th><th style=\"text-align: right;\">    lag_2</th><th style=\"text-align: right;\">    lag_3</th><th style=\"text-align: right;\">    lag_4</th><th style=\"text-align: right;\">    lag_5</th><th style=\"text-align: right;\">    lag_6</th><th style=\"text-align: right;\">    lag_7</th><th style=\"text-align: right;\">    lag_8</th><th style=\"text-align: right;\">    lag_9</th><th style=\"text-align: right;\">   lag_10</th><th style=\"text-align: right;\">   lag_11</th><th style=\"text-align: right;\">   lag_12</th><th style=\"text-align: right;\">   lag_13</th><th style=\"text-align: right;\">   lag_14</th><th style=\"text-align: right;\">  frac_diff_log</th><th style=\"text-align: right;\">     volat</th><th style=\"text-align: right;\">  outcome_w_metalabels</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">-0.90511 </td><td style=\"text-align: right;\">-1.42706  </td><td style=\"text-align: right;\">-0.92388 </td><td style=\"text-align: right;\">-0.92828 </td><td style=\"text-align: right;\">-0.946386</td><td style=\"text-align: right;\">-0.918814</td><td style=\"text-align: right;\">-0.924206</td><td style=\"text-align: right;\">-0.950972</td><td style=\"text-align: right;\">-1.00526   </td><td style=\"text-align: right;\"> 0.251333</td><td style=\"text-align: right;\"> 0.521431</td><td style=\"text-align: right;\"> 0.646326 </td><td style=\"text-align: right;\"> -0.937658</td><td style=\"text-align: right;\">  -0.92828 </td><td style=\"text-align: right;\"> -0.917702</td><td style=\"text-align: right;\"> 0.493196</td><td style=\"text-align: right;\"> 0.382857</td><td style=\"text-align: right;\"> 0.688054</td><td style=\"text-align: right;\">      0.535873 </td><td style=\"text-align: right;\"> 0.255412</td><td style=\"text-align: right;\">   -0.0528361</td><td style=\"text-align: right;\">    0.0528361</td><td style=\"text-align: right;\">-0.90979 </td><td style=\"text-align: right;\">-0.914642</td><td style=\"text-align: right;\">-0.90561 </td><td style=\"text-align: right;\">-0.924521</td><td style=\"text-align: right;\">-0.950547</td><td style=\"text-align: right;\">-0.930581</td><td style=\"text-align: right;\">-0.921709</td><td style=\"text-align: right;\">-0.924996</td><td style=\"text-align: right;\">-0.94912 </td><td style=\"text-align: right;\">-0.918055</td><td style=\"text-align: right;\">-0.916309</td><td style=\"text-align: right;\">-0.905016</td><td style=\"text-align: right;\">-0.903132</td><td style=\"text-align: right;\">-0.909413</td><td style=\"text-align: right;\">      -0.687138</td><td style=\"text-align: right;\">-0.355501 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.899383</td><td style=\"text-align: right;\"> 0.251357 </td><td style=\"text-align: right;\">-0.900809</td><td style=\"text-align: right;\">-0.91293 </td><td style=\"text-align: right;\">-0.940176</td><td style=\"text-align: right;\">-0.903259</td><td style=\"text-align: right;\">-0.911606</td><td style=\"text-align: right;\">-0.944899</td><td style=\"text-align: right;\"> 0.424744  </td><td style=\"text-align: right;\"> 0.488242</td><td style=\"text-align: right;\"> 0.141591</td><td style=\"text-align: right;\"> 0.686693 </td><td style=\"text-align: right;\"> -0.92895 </td><td style=\"text-align: right;\">  -0.91293 </td><td style=\"text-align: right;\"> -0.895781</td><td style=\"text-align: right;\"> 0.431009</td><td style=\"text-align: right;\"> 0.401293</td><td style=\"text-align: right;\"> 0.711118</td><td style=\"text-align: right;\">      0.385304 </td><td style=\"text-align: right;\"> 0.528465</td><td style=\"text-align: right;\">   -0.110511 </td><td style=\"text-align: right;\">    0.110511 </td><td style=\"text-align: right;\">-0.89712 </td><td style=\"text-align: right;\">-0.897286</td><td style=\"text-align: right;\">-0.896758</td><td style=\"text-align: right;\">-0.893628</td><td style=\"text-align: right;\">-0.886853</td><td style=\"text-align: right;\">-0.905068</td><td style=\"text-align: right;\">-0.909734</td><td style=\"text-align: right;\">-0.914583</td><td style=\"text-align: right;\">-0.905558</td><td style=\"text-align: right;\">-0.924477</td><td style=\"text-align: right;\">-0.950499</td><td style=\"text-align: right;\">-0.930527</td><td style=\"text-align: right;\">-0.921702</td><td style=\"text-align: right;\">-0.925032</td><td style=\"text-align: right;\">      -0.72257 </td><td style=\"text-align: right;\">-0.4165   </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.959781</td><td style=\"text-align: right;\">-0.0427553</td><td style=\"text-align: right;\">-0.9198  </td><td style=\"text-align: right;\">-0.918929</td><td style=\"text-align: right;\">-0.937366</td><td style=\"text-align: right;\">-0.930505</td><td style=\"text-align: right;\">-0.924654</td><td style=\"text-align: right;\">-0.944893</td><td style=\"text-align: right;\"> 0.256032  </td><td style=\"text-align: right;\">-1.42039 </td><td style=\"text-align: right;\">-0.155401</td><td style=\"text-align: right;\"> 0.261012 </td><td style=\"text-align: right;\"> -0.92608 </td><td style=\"text-align: right;\">  -0.918929</td><td style=\"text-align: right;\"> -0.910576</td><td style=\"text-align: right;\">-0.967177</td><td style=\"text-align: right;\">-0.61703 </td><td style=\"text-align: right;\"> 0.194902</td><td style=\"text-align: right;\">     -1.27079  </td><td style=\"text-align: right;\"> 0.103568</td><td style=\"text-align: right;\">   -0.112111 </td><td style=\"text-align: right;\">    0.112111 </td><td style=\"text-align: right;\">-0.959254</td><td style=\"text-align: right;\">-0.927311</td><td style=\"text-align: right;\">-0.942404</td><td style=\"text-align: right;\">-0.923132</td><td style=\"text-align: right;\">-0.899349</td><td style=\"text-align: right;\">-0.897085</td><td style=\"text-align: right;\">-0.897238</td><td style=\"text-align: right;\">-0.896707</td><td style=\"text-align: right;\">-0.893583</td><td style=\"text-align: right;\">-0.886816</td><td style=\"text-align: right;\">-0.905028</td><td style=\"text-align: right;\">-0.909701</td><td style=\"text-align: right;\">-0.914587</td><td style=\"text-align: right;\">-0.905594</td><td style=\"text-align: right;\">      -0.987445</td><td style=\"text-align: right;\">-0.456314 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.00126 </td><td style=\"text-align: right;\">-0.579148 </td><td style=\"text-align: right;\">-0.94308 </td><td style=\"text-align: right;\">-0.926083</td><td style=\"text-align: right;\">-0.936615</td><td style=\"text-align: right;\">-0.951868</td><td style=\"text-align: right;\">-0.937983</td><td style=\"text-align: right;\">-0.946709</td><td style=\"text-align: right;\">-0.221606  </td><td style=\"text-align: right;\">-2.02588 </td><td style=\"text-align: right;\">-1.01881 </td><td style=\"text-align: right;\">-0.0313368</td><td style=\"text-align: right;\"> -0.914623</td><td style=\"text-align: right;\">  -0.926083</td><td style=\"text-align: right;\"> -0.936192</td><td style=\"text-align: right;\">-1.31482 </td><td style=\"text-align: right;\">-1.04508 </td><td style=\"text-align: right;\">-0.128911</td><td style=\"text-align: right;\">     -1.80872  </td><td style=\"text-align: right;\">-0.707903</td><td style=\"text-align: right;\">   -0.104202 </td><td style=\"text-align: right;\">    0.104202 </td><td style=\"text-align: right;\">-0.977651</td><td style=\"text-align: right;\">-0.941543</td><td style=\"text-align: right;\">-0.959759</td><td style=\"text-align: right;\">-0.959232</td><td style=\"text-align: right;\">-0.927291</td><td style=\"text-align: right;\">-0.942383</td><td style=\"text-align: right;\">-0.923098</td><td style=\"text-align: right;\">-0.89931 </td><td style=\"text-align: right;\">-0.897054</td><td style=\"text-align: right;\">-0.897229</td><td style=\"text-align: right;\">-0.896698</td><td style=\"text-align: right;\">-0.893561</td><td style=\"text-align: right;\">-0.886819</td><td style=\"text-align: right;\">-0.905074</td><td style=\"text-align: right;\">      -1.20229 </td><td style=\"text-align: right;\">-0.349466 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.02105 </td><td style=\"text-align: right;\">-0.0954012</td><td style=\"text-align: right;\">-0.955475</td><td style=\"text-align: right;\">-0.929608</td><td style=\"text-align: right;\">-0.936841</td><td style=\"text-align: right;\">-0.964505</td><td style=\"text-align: right;\">-0.945951</td><td style=\"text-align: right;\">-0.948226</td><td style=\"text-align: right;\"> 0.19508   </td><td style=\"text-align: right;\">-2.41435 </td><td style=\"text-align: right;\">-1.0174  </td><td style=\"text-align: right;\">-0.170784 </td><td style=\"text-align: right;\"> -0.905901</td><td style=\"text-align: right;\">  -0.929608</td><td style=\"text-align: right;\"> -0.951867</td><td style=\"text-align: right;\">-1.51913 </td><td style=\"text-align: right;\">-1.24964 </td><td style=\"text-align: right;\">-0.273968</td><td style=\"text-align: right;\">     -2.18837  </td><td style=\"text-align: right;\">-1.12765 </td><td style=\"text-align: right;\">   -0.111963 </td><td style=\"text-align: right;\">    0.111963 </td><td style=\"text-align: right;\">-1.00125 </td><td style=\"text-align: right;\">-0.977643</td><td style=\"text-align: right;\">-0.941536</td><td style=\"text-align: right;\">-0.959753</td><td style=\"text-align: right;\">-0.959225</td><td style=\"text-align: right;\">-0.927283</td><td style=\"text-align: right;\">-0.942362</td><td style=\"text-align: right;\">-0.923087</td><td style=\"text-align: right;\">-0.89931 </td><td style=\"text-align: right;\">-0.897055</td><td style=\"text-align: right;\">-0.897218</td><td style=\"text-align: right;\">-0.896685</td><td style=\"text-align: right;\">-0.893587</td><td style=\"text-align: right;\">-0.88685 </td><td style=\"text-align: right;\">      -1.26802 </td><td style=\"text-align: right;\">-0.268272 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.04587 </td><td style=\"text-align: right;\">-0.253263 </td><td style=\"text-align: right;\">-0.970126</td><td style=\"text-align: right;\">-0.935677</td><td style=\"text-align: right;\">-0.937316</td><td style=\"text-align: right;\">-0.979358</td><td style=\"text-align: right;\">-0.955525</td><td style=\"text-align: right;\">-0.950207</td><td style=\"text-align: right;\"> 0.00397166</td><td style=\"text-align: right;\">-2.85387 </td><td style=\"text-align: right;\">-1.74703 </td><td style=\"text-align: right;\">-0.345704 </td><td style=\"text-align: right;\"> -0.896137</td><td style=\"text-align: right;\">  -0.935677</td><td style=\"text-align: right;\"> -0.973643</td><td style=\"text-align: right;\">-1.73339 </td><td style=\"text-align: right;\">-1.48005 </td><td style=\"text-align: right;\">-0.450759</td><td style=\"text-align: right;\">     -2.59914  </td><td style=\"text-align: right;\">-1.53324 </td><td style=\"text-align: right;\">   -0.110727 </td><td style=\"text-align: right;\">    0.110727 </td><td style=\"text-align: right;\">-1.02104 </td><td style=\"text-align: right;\">-1.00125 </td><td style=\"text-align: right;\">-0.977636</td><td style=\"text-align: right;\">-0.941529</td><td style=\"text-align: right;\">-0.959746</td><td style=\"text-align: right;\">-0.959218</td><td style=\"text-align: right;\">-0.927263</td><td style=\"text-align: right;\">-0.942352</td><td style=\"text-align: right;\">-0.923087</td><td style=\"text-align: right;\">-0.899311</td><td style=\"text-align: right;\">-0.897045</td><td style=\"text-align: right;\">-0.897206</td><td style=\"text-align: right;\">-0.896711</td><td style=\"text-align: right;\">-0.893619</td><td style=\"text-align: right;\">      -1.36977 </td><td style=\"text-align: right;\">-0.205165 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.04934 </td><td style=\"text-align: right;\">-0.758567 </td><td style=\"text-align: right;\">-0.982747</td><td style=\"text-align: right;\">-0.942865</td><td style=\"text-align: right;\">-0.937826</td><td style=\"text-align: right;\">-0.992141</td><td style=\"text-align: right;\">-0.964519</td><td style=\"text-align: right;\">-0.952217</td><td style=\"text-align: right;\">-0.388361  </td><td style=\"text-align: right;\">-2.4617  </td><td style=\"text-align: right;\">-2.06679 </td><td style=\"text-align: right;\">-0.370168 </td><td style=\"text-align: right;\"> -0.891635</td><td style=\"text-align: right;\">  -0.942865</td><td style=\"text-align: right;\"> -0.992424</td><td style=\"text-align: right;\">-1.76126 </td><td style=\"text-align: right;\">-1.51075 </td><td style=\"text-align: right;\">-0.47513 </td><td style=\"text-align: right;\">     -2.7463   </td><td style=\"text-align: right;\">-1.88448 </td><td style=\"text-align: right;\">   -0.0980563</td><td style=\"text-align: right;\">    0.0980563</td><td style=\"text-align: right;\">-1.04586 </td><td style=\"text-align: right;\">-1.02103 </td><td style=\"text-align: right;\">-1.00124 </td><td style=\"text-align: right;\">-0.977629</td><td style=\"text-align: right;\">-0.941523</td><td style=\"text-align: right;\">-0.959738</td><td style=\"text-align: right;\">-0.959197</td><td style=\"text-align: right;\">-0.927252</td><td style=\"text-align: right;\">-0.942351</td><td style=\"text-align: right;\">-0.923088</td><td style=\"text-align: right;\">-0.899301</td><td style=\"text-align: right;\">-0.897032</td><td style=\"text-align: right;\">-0.897232</td><td style=\"text-align: right;\">-0.896743</td><td style=\"text-align: right;\">      -1.31142 </td><td style=\"text-align: right;\">-0.102075 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.01914 </td><td style=\"text-align: right;\"> 0.989413 </td><td style=\"text-align: right;\">-0.99042 </td><td style=\"text-align: right;\">-0.948092</td><td style=\"text-align: right;\">-0.938032</td><td style=\"text-align: right;\">-0.997108</td><td style=\"text-align: right;\">-0.969778</td><td style=\"text-align: right;\">-0.953587</td><td style=\"text-align: right;\"> 1.08591   </td><td style=\"text-align: right;\">-1.49912 </td><td style=\"text-align: right;\">-1.50421 </td><td style=\"text-align: right;\">-0.157328 </td><td style=\"text-align: right;\"> -0.892441</td><td style=\"text-align: right;\">  -0.948092</td><td style=\"text-align: right;\"> -1.00203 </td><td style=\"text-align: right;\">-0.927029</td><td style=\"text-align: right;\">-0.957717</td><td style=\"text-align: right;\">-0.242085</td><td style=\"text-align: right;\">     -2.30977  </td><td style=\"text-align: right;\">-2.07554 </td><td style=\"text-align: right;\">   -0.0858206</td><td style=\"text-align: right;\">    0.0858206</td><td style=\"text-align: right;\">-1.04933 </td><td style=\"text-align: right;\">-1.04585 </td><td style=\"text-align: right;\">-1.02102 </td><td style=\"text-align: right;\">-1.00123 </td><td style=\"text-align: right;\">-0.977622</td><td style=\"text-align: right;\">-0.941515</td><td style=\"text-align: right;\">-0.959717</td><td style=\"text-align: right;\">-0.959186</td><td style=\"text-align: right;\">-0.927252</td><td style=\"text-align: right;\">-0.942353</td><td style=\"text-align: right;\">-0.923078</td><td style=\"text-align: right;\">-0.899288</td><td style=\"text-align: right;\">-0.897058</td><td style=\"text-align: right;\">-0.897264</td><td style=\"text-align: right;\">      -1.05539 </td><td style=\"text-align: right;\">-0.0524798</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.03163 </td><td style=\"text-align: right;\">-2.01751  </td><td style=\"text-align: right;\">-1.02387 </td><td style=\"text-align: right;\">-0.978495</td><td style=\"text-align: right;\">-0.93911 </td><td style=\"text-align: right;\">-1.01389 </td><td style=\"text-align: right;\">-0.990457</td><td style=\"text-align: right;\">-0.96016 </td><td style=\"text-align: right;\">-1.71724   </td><td style=\"text-align: right;\">-1.05749 </td><td style=\"text-align: right;\">-1.93875 </td><td style=\"text-align: right;\">-0.2454   </td><td style=\"text-align: right;\"> -0.926336</td><td style=\"text-align: right;\">  -0.978495</td><td style=\"text-align: right;\"> -1.02893 </td><td style=\"text-align: right;\">-0.82963 </td><td style=\"text-align: right;\">-0.919856</td><td style=\"text-align: right;\">-0.317636</td><td style=\"text-align: right;\">     -0.792821 </td><td style=\"text-align: right;\">-2.25434 </td><td style=\"text-align: right;\">    0.038803 </td><td style=\"text-align: right;\">   -0.038803 </td><td style=\"text-align: right;\">-1.02833 </td><td style=\"text-align: right;\">-1.03821 </td><td style=\"text-align: right;\">-0.99881 </td><td style=\"text-align: right;\">-1.00297 </td><td style=\"text-align: right;\">-1.0191  </td><td style=\"text-align: right;\">-1.04929 </td><td style=\"text-align: right;\">-1.0458  </td><td style=\"text-align: right;\">-1.02097 </td><td style=\"text-align: right;\">-1.00119 </td><td style=\"text-align: right;\">-0.977584</td><td style=\"text-align: right;\">-0.941474</td><td style=\"text-align: right;\">-0.959684</td><td style=\"text-align: right;\">-0.959189</td><td style=\"text-align: right;\">-0.927289</td><td style=\"text-align: right;\">      -1.13731 </td><td style=\"text-align: right;\"> 0.148809 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-1.02608 </td><td style=\"text-align: right;\"> 0.398154 </td><td style=\"text-align: right;\">-1.0247  </td><td style=\"text-align: right;\">-0.997638</td><td style=\"text-align: right;\">-0.939923</td><td style=\"text-align: right;\">-1.01932 </td><td style=\"text-align: right;\">-0.999714</td><td style=\"text-align: right;\">-0.9641  </td><td style=\"text-align: right;\"> 0.285645  </td><td style=\"text-align: right;\"> 0.38589 </td><td style=\"text-align: right;\">-1.82192 </td><td style=\"text-align: right;\">-0.206257 </td><td style=\"text-align: right;\"> -0.967417</td><td style=\"text-align: right;\">  -0.997638</td><td style=\"text-align: right;\"> -1.02627 </td><td style=\"text-align: right;\">-0.678781</td><td style=\"text-align: right;\">-0.819203</td><td style=\"text-align: right;\">-0.275315</td><td style=\"text-align: right;\">     -0.0885674</td><td style=\"text-align: right;\">-1.59228 </td><td style=\"text-align: right;\">   -0.10813  </td><td style=\"text-align: right;\">    0.10813  </td><td style=\"text-align: right;\">-1.02555 </td><td style=\"text-align: right;\">-1.02485 </td><td style=\"text-align: right;\">-1.03161 </td><td style=\"text-align: right;\">-1.02831 </td><td style=\"text-align: right;\">-1.03819 </td><td style=\"text-align: right;\">-0.998788</td><td style=\"text-align: right;\">-1.00293 </td><td style=\"text-align: right;\">-1.01906 </td><td style=\"text-align: right;\">-1.04926 </td><td style=\"text-align: right;\">-1.04579 </td><td style=\"text-align: right;\">-1.02096 </td><td style=\"text-align: right;\">-1.00116 </td><td style=\"text-align: right;\">-0.977585</td><td style=\"text-align: right;\">-0.94152 </td><td style=\"text-align: right;\">      -1.0809  </td><td style=\"text-align: right;\"> 0.320719 </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10071 rows x 39 columns]</pre>"
      ],
      "text/plain": [
       "    close     returns     sma_10     sma_20    sma_100     ema_10     ema_20    ema_100      z-score     roc_10     roc_20     roc_100    bb_upper    bb_middle    bb_lower     rsi_10     rsi_20    rsi_100    log_macd_hist    log_dpo    gmm_state_0    gmm_state_1      lag_1      lag_2      lag_3      lag_4      lag_5      lag_6      lag_7      lag_8      lag_9     lag_10     lag_11     lag_12     lag_13     lag_14    frac_diff_log       volat    outcome_w_metalabels\n",
       "---------  ----------  ---------  ---------  ---------  ---------  ---------  ---------  -----------  ---------  ---------  ----------  ----------  -----------  ----------  ---------  ---------  ---------  ---------------  ---------  -------------  -------------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------------  ----------  ----------------------\n",
       "-0.90511   -1.42706    -0.92388   -0.92828   -0.946386  -0.918814  -0.924206  -0.950972  -1.00526      0.251333   0.521431   0.646326    -0.937658    -0.92828    -0.917702   0.493196   0.382857   0.688054        0.535873    0.255412     -0.0528361      0.0528361  -0.90979   -0.914642  -0.90561   -0.924521  -0.950547  -0.930581  -0.921709  -0.924996  -0.94912   -0.918055  -0.916309  -0.905016  -0.903132  -0.909413        -0.687138  -0.355501                        1\n",
       "-0.899383   0.251357   -0.900809  -0.91293   -0.940176  -0.903259  -0.911606  -0.944899   0.424744     0.488242   0.141591   0.686693    -0.92895     -0.91293    -0.895781   0.431009   0.401293   0.711118        0.385304    0.528465     -0.110511       0.110511   -0.89712   -0.897286  -0.896758  -0.893628  -0.886853  -0.905068  -0.909734  -0.914583  -0.905558  -0.924477  -0.950499  -0.930527  -0.921702  -0.925032        -0.72257   -0.4165                          1\n",
       "-0.959781  -0.0427553  -0.9198    -0.918929  -0.937366  -0.930505  -0.924654  -0.944893   0.256032    -1.42039   -0.155401   0.261012    -0.92608     -0.918929   -0.910576  -0.967177  -0.61703    0.194902       -1.27079     0.103568     -0.112111       0.112111   -0.959254  -0.927311  -0.942404  -0.923132  -0.899349  -0.897085  -0.897238  -0.896707  -0.893583  -0.886816  -0.905028  -0.909701  -0.914587  -0.905594        -0.987445  -0.456314                        1\n",
       "-1.00126   -0.579148   -0.94308   -0.926083  -0.936615  -0.951868  -0.937983  -0.946709  -0.221606    -2.02588   -1.01881   -0.0313368   -0.914623    -0.926083   -0.936192  -1.31482   -1.04508   -0.128911       -1.80872    -0.707903     -0.104202       0.104202   -0.977651  -0.941543  -0.959759  -0.959232  -0.927291  -0.942383  -0.923098  -0.89931   -0.897054  -0.897229  -0.896698  -0.893561  -0.886819  -0.905074        -1.20229   -0.349466                        1\n",
       "-1.02105   -0.0954012  -0.955475  -0.929608  -0.936841  -0.964505  -0.945951  -0.948226   0.19508     -2.41435   -1.0174    -0.170784    -0.905901    -0.929608   -0.951867  -1.51913   -1.24964   -0.273968       -2.18837    -1.12765      -0.111963       0.111963   -1.00125   -0.977643  -0.941536  -0.959753  -0.959225  -0.927283  -0.942362  -0.923087  -0.89931   -0.897055  -0.897218  -0.896685  -0.893587  -0.88685         -1.26802   -0.268272                        1\n",
       "-1.04587   -0.253263   -0.970126  -0.935677  -0.937316  -0.979358  -0.955525  -0.950207   0.00397166  -2.85387   -1.74703   -0.345704    -0.896137    -0.935677   -0.973643  -1.73339   -1.48005   -0.450759       -2.59914    -1.53324      -0.110727       0.110727   -1.02104   -1.00125   -0.977636  -0.941529  -0.959746  -0.959218  -0.927263  -0.942352  -0.923087  -0.899311  -0.897045  -0.897206  -0.896711  -0.893619        -1.36977   -0.205165                        1\n",
       "-1.04934   -0.758567   -0.982747  -0.942865  -0.937826  -0.992141  -0.964519  -0.952217  -0.388361    -2.4617    -2.06679   -0.370168    -0.891635    -0.942865   -0.992424  -1.76126   -1.51075   -0.47513        -2.7463     -1.88448      -0.0980563      0.0980563  -1.04586   -1.02103   -1.00124   -0.977629  -0.941523  -0.959738  -0.959197  -0.927252  -0.942351  -0.923088  -0.899301  -0.897032  -0.897232  -0.896743        -1.31142   -0.102075                        1\n",
       "-1.01914    0.989413   -0.99042   -0.948092  -0.938032  -0.997108  -0.969778  -0.953587   1.08591     -1.49912   -1.50421   -0.157328    -0.892441    -0.948092   -1.00203   -0.927029  -0.957717  -0.242085       -2.30977    -2.07554      -0.0858206      0.0858206  -1.04933   -1.04585   -1.02102   -1.00123   -0.977622  -0.941515  -0.959717  -0.959186  -0.927252  -0.942353  -0.923078  -0.899288  -0.897058  -0.897264        -1.05539   -0.0524798                       1\n",
       "-1.03163   -2.01751    -1.02387   -0.978495  -0.93911   -1.01389   -0.990457  -0.96016   -1.71724     -1.05749   -1.93875   -0.2454      -0.926336    -0.978495   -1.02893   -0.82963   -0.919856  -0.317636       -0.792821   -2.25434       0.038803      -0.038803   -1.02833   -1.03821   -0.99881   -1.00297   -1.0191    -1.04929   -1.0458    -1.02097   -1.00119   -0.977584  -0.941474  -0.959684  -0.959189  -0.927289        -1.13731    0.148809                        1\n",
       "-1.02608    0.398154   -1.0247    -0.997638  -0.939923  -1.01932   -0.999714  -0.9641     0.285645     0.38589   -1.82192   -0.206257    -0.967417    -0.997638   -1.02627   -0.678781  -0.819203  -0.275315       -0.0885674  -1.59228      -0.10813        0.10813    -1.02555   -1.02485   -1.03161   -1.02831   -1.03819   -0.998788  -1.00293   -1.01906   -1.04926   -1.04579   -1.02096   -1.00116   -0.977585  -0.94152         -1.0809     0.320719                        1\n",
       "[10071 rows x 39 columns]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_profit(\n",
    "    predicted_outcomes: np.ndarray,\n",
    "    \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "                                            model_id  accuracy  sharpe_ratio  \\\n",
      "0                      GBM_1_AutoML_4_20240730_11540  0.901797     70.066398   \n",
      "1  StackedEnsemble_BestOfFamily_1_AutoML_4_202407...  0.946242     83.411855   \n",
      "2                      GLM_1_AutoML_4_20240730_11540  0.529902   1108.036100   \n",
      "\n",
      "   max_drawdown  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_id in lb.as_data_frame()['model_id']:\n",
    "    model = h2o.get_model(model_id)\n",
    "    preddd = model.predict(test)\n",
    "    \n",
    "    preddd_df = preddd.as_data_frame()\n",
    "    actuals = test[y].as_data_frame()\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, preddd_df['predict'])\n",
    "    \n",
    "    returns = preddd_df['predict'].astype(float).values  # Assuming returns are in the 'predict' column\n",
    "    sharpe_ratio_value = sharpe_ratio(returns)\n",
    "    max_drawdown_value = max_drawdown(returns)\n",
    "    \n",
    "    results.append({\n",
    "        'model_id': model_id,\n",
    "        'accuracy': accuracy,\n",
    "        'sharpe_ratio': sharpe_ratio_value,\n",
    "        'max_drawdown': max_drawdown_value\n",
    "    })\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrong sharpe, will fix soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  32%|███▎      | 13/40 [28:53<46:38, 103.64s/pipeline] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x0000027F099A0990>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kalulu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 582, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  35%|███▌      | 14/40 [29:03<34:59, 80.77s/pipeline] "
     ]
    }
   ],
   "source": [
    "meta = TPOTClassifier(generations = 3, population_size = 10, warm_start = True, verbosity = 2)\n",
    "meta.fit(X_train_meta, y_train_meta)\n",
    "print(meta.score(X_test_meta, y_test_meta))\n",
    "\n",
    "print(\"\\nBest Pipeline:\\n\")\n",
    "print(meta.fitted_pipeline_)\n",
    "meta.export('best_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
